____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
lambda_1 (Lambda)                (None, 160, 320, 3)   0           lambda_input_1[0][0]             
____________________________________________________________________________________________________
cropping2d_1 (Cropping2D)        (None, 90, 320, 3)    0           lambda_1[0][0]                   
____________________________________________________________________________________________________
convolution2d_1 (Convolution2D)  (None, 43, 158, 24)   1824        cropping2d_1[0][0]               
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (None, 20, 77, 36)    21636       convolution2d_1[0][0]            
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (None, 8, 37, 48)     43248       convolution2d_2[0][0]            
____________________________________________________________________________________________________
convolution2d_4 (Convolution2D)  (None, 6, 35, 64)     27712       convolution2d_3[0][0]            
____________________________________________________________________________________________________
convolution2d_5 (Convolution2D)  (None, 4, 33, 64)     36928       convolution2d_4[0][0]            
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 8448)          0           convolution2d_5[0][0]            
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 100)           844900      flatten_1[0][0]                  
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 50)            5050        dense_1[0][0]                    
____________________________________________________________________________________________________
dense_3 (Dense)                  (None, 10)            510         dense_2[0][0]                    
____________________________________________________________________________________________________
dense_4 (Dense)                  (None, 1)             11          dense_3[0][0]                    
====================================================================================================
Total params: 981,819
Trainable params: 981,819
Non-trainable params: 0
____________________________________________________________________________________________________
Epoch 1/8
33792/33808 [============================>.] - ETA: 0s - loss: 0.0249
C:\Users\paul-otniel.barna\AppData\Local\Continuum\miniconda3\envs\paulbarna\lib\site-packages\keras\engine\training.py:1569: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.
  warnings.warn('Epoch comprised more than '
Epoch 00000: val_loss improved from inf to 0.02034, saving model to model.h5
33856/33808 [==============================] - 893s - loss: 0.0249 - val_loss: 0.0203
Epoch 2/8
33760/33808 [============================>.] - ETA: 1s - loss: 0.0199Epoch 00001: val_loss improved from 0.02034 to 0.01715, saving model to model.h5
33824/33808 [==============================] - 893s - loss: 0.0199 - val_loss: 0.0172
Epoch 3/8
33792/33808 [============================>.] - ETA: 0s - loss: 0.0180Epoch 00002: val_loss did not improve
33856/33808 [==============================] - 917s - loss: 0.0180 - val_loss: 0.0172
Epoch 4/8
33760/33808 [============================>.] - ETA: 1s - loss: 0.0176Epoch 00003: val_loss did not improve
33824/33808 [==============================] - 909s - loss: 0.0176 - val_loss: 0.0176
Epoch 5/8
33792/33808 [============================>.] - ETA: 0s - loss: 0.0161Epoch 00004: val_loss did not improve
33856/33808 [==============================] - 900s - loss: 0.0162 - val_loss: 0.0177
Epoch 6/8
33760/33808 [============================>.] - ETA: 1s - loss: 0.0163Epoch 00005: val_loss improved from 0.01715 to 0.01513, saving model to model.h5
33824/33808 [==============================] - 887s - loss: 0.0163 - val_loss: 0.0151
Epoch 7/8
33792/33808 [============================>.] - ETA: 0s - loss: 0.0154Epoch 00006: val_loss improved from 0.01513 to 0.01488, saving model to model.h5
33856/33808 [==============================] - 907s - loss: 0.0154 - val_loss: 0.0149
Epoch 8/8
33760/33808 [============================>.] - ETA: 1s - loss: 0.0151Epoch 00007: val_loss improved from 0.01488 to 0.01420, saving model to model.h5
33824/33808 [==============================] - 898s - loss: 0.0151 - val_loss: 0.0142
dict_keys(['loss', 'val_loss'])
Loss
[0.024866683375167824, 0.019898606340912794, 0.018049063481432728, 0.017613978370981838, 0.016156118274235038, 0.016319308314532353, 0.015385238766240657, 0.015050647100090079]
Validation Loss
[0.020341040706612114, 0.017154889239174912, 0.017187780966716155, 0.017635420511823988, 0.017743231749680257, 0.015133406890507326, 0.014880789002697719, 0.014196805975279449]
